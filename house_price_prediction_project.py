# -*- coding: utf-8 -*-
"""House Price Prediction project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17wK3O2R8Jz2CmV5TXlYXbkmzG9j2Z_3l
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import matplotlib
matplotlib.rcParams["figure.figsize"] = (20,10)

from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import cross_val_score

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("Bengaluru_House_Data.csv")
df.head()

df.shape

""" EDA (Exploratory Data Analysis)

"""

df.columns

df.info()

df.describe()

df.isnull()

df.isnull().sum() #check to see null values

df.groupby('area_type')['area_type'].agg('count')

df.info()

df.head()

# drop less important features
df= df.drop(['area_type','availability','society','balcony'],axis='columns')

df.shape

# drop null values
df = df.dropna()

df.isnull().sum()

"""Feature engineering"""

df['size'].unique()

df['BHK'] = df['size'].apply(lambda x: int(x.split(' ')[0]))

df.head()

df.total_sqft.unique()

def is_float(x):
    try:
        float(x)
    except:
        return False
    return True

df[~df['total_sqft'].apply(is_float)].head(10)

def convert_sqft_to_num(x):
    tokens = x.split('-')
    if len(tokens) == 2:
        return (float(tokens[0])+float(tokens[1]))/2
    try:
        return float(x)
    except:
        return None

df= df.copy()
df['total_sqft'] = df['total_sqft'].apply(convert_sqft_to_num)
df.head(10)

"""ADD A NEW FEATURE CALLED "PRICE PER SQUARE FEET"
"""

df= df.copy()
df['price_per_sqft'] = df['price']*100000/df['total_sqft']
df.head()

"""Using Dimensionality reduction to reduce number of locations"""

df.location = df.location.apply(lambda x: x.strip())
location_stats = df.groupby('location')['location'].agg('count').sort_values(ascending=False)
location_stats

len(location_stats[location_stats<=10])

location_stats_less_than_10 = location_stats[location_stats<=10]
location_stats_less_than_10

df.location = df.location.apply(lambda x: 'other' if x in location_stats_less_than_10 else x)
len(df.location.unique())

df.head()

df[df.total_sqft/df.BHK<300].head()

df=df[~(df.total_sqft/df.BHK<300)]
df.shape

df.describe()

"""Remove outliners (as our range is between 267 rs/sqft whereas max is 12000000)"""

def remove_pps_outliers(df):
    df_out = pd.DataFrame()
    for key, subdf in df.groupby('location'):
        m = np.mean(subdf.price_per_sqft)
        st = np.std(subdf.price_per_sqft)
        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]
        df_out = pd.concat([df_out,reduced_df],ignore_index=True)
    return df_out
df = remove_pps_outliers(df)
df.shape

df.head()

"""Data Vizualization


"""

df.head(20)

# Ploting the Scatter Chart for 2 BHK and 3 BHK properties
def plot_scatter_chart(df,location):
    bhk2 = df[(df.location==location) & (df.BHK==2)]
    bhk3 = df[(df.location==location) & (df.BHK==3)]
    matplotlib.rcParams['figure.figsize'] = (8,6)
    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)
    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)
    plt.xlabel("Total Square Feet Area")
    plt.ylabel("Price (Lakh Indian Rupees)")
    plt.title(location)
    plt.legend()

plot_scatter_chart(df,"1st Phase JP Nagar")

# Ploting the histogram for Price Per Square Feet and Count
plt.hist(df.price_per_sqft,rwidth=0.8)
plt.xlabel("Price Per Square Feet")
plt.ylabel("Count")

# Ploting the histogram for Number of bathrooms and Count
plt.hist(df.bath,rwidth=0.8)
plt.xlabel("Number of bathrooms")
plt.ylabel("Count")

df[df.bath>10]

df[df.bath>df.BHK+2]

df.head()

df.shape

"""Using One Hot Encoding for Location


"""

dummies = pd.get_dummies(df.location)
dummies.head(20)

"""Concatinating the dataframes together


"""

df = pd.concat([df,dummies.drop('other',axis='columns')],axis='columns')
df.head()

df = df.drop('location',axis='columns')
df.head()

X = df.drop(['price'],axis='columns')
X.head()

X = df.drop(['size'],axis='columns')
X.head()

y = df.price
y.head()

X = X.drop(['price_per_sqft'],axis='columns')
X.head()

X = X.drop(['price'],axis='columns')
X.head()

X.shape

y.shape

"""
Train-Test Split"""

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)

lr_clf = LinearRegression()
lr_clf.fit(X_train,y_train)
lr_clf.score(X_test,y_test)

cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
cross_val_score(LinearRegression(), X, y, cv=cv)

"""using Grid Search CV for 3 different types of Regression models.


-Linear Regression
-Lasso Regression
-Decision Tree Regression

**Model Building**
"""

def find_best_model_using_gridsearchcv(X, y):
    algos = {
        'linear_regression': {
            'model': LinearRegression(),
            'params': {
                'fit_intercept': [True, False]
            }
        },
        'lasso': {
            'model': Lasso(),
            'params': {
                'alpha': [1, 2],
                'selection': ['random', 'cyclic']
            }
        },
        'decision_tree': {
            'model': DecisionTreeRegressor(),
            'params': {
                'criterion': ['squared_error', 'friedman_mse'],
                'splitter': ['best', 'random']
            }
        }
    }

    scores = []
    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)

    for algo_name, config in algos.items():
        gs = GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)
        gs.fit(X, y)
        scores.append({
            'model': algo_name,
            'best_score': gs.best_score_,
            'best_params': gs.best_params_
        })

    return pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])

"""Model Evaluation


"""

best_model_df = find_best_model_using_gridsearchcv(X, y)
print(best_model_df)

"""The best one is linear regression

Model Testing
"""

def predict_price(location,sqft,bath,bhk):
    loc_index = np.where(X.columns==location)[0][0]

    x = np.zeros(len(X.columns))
    x[0] = sqft
    x[1] = bath
    x[2] = bhk
    if loc_index >= 0:
        x[loc_index] = 1

    return lr_clf.predict([x])[0]

predict_price('1st Phase JP Nagar',1000, 2, 2)

df.head()

predict_price('Banashankari Stage V',2000, 3, 3)

predict_price('2nd Stage Nagarbhavi',5000, 2, 2)

predict_price('Indira Nagar',1500, 3, 3)